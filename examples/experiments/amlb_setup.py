# full_experiment.py
import pandas as pd
import numpy as np
import time
import json
from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score

from core.repository.constant_repo import AmlbExperimentDataset
from examples.experiments.amlb_dataloader import AMLBDatasetLoader
from examples.experiments.fedot_integration import FedotSamplingEnsemble


class LargeScaleAutoMLExperiment:
    """
    –ü–æ–ª–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é Fedot + Sampling-Zoo —Å –¥—Ä—É–≥–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
    """

    def __init__(self, results_path: str = "experiment_results"):
        self.results_path = results_path
        self.loader = AMLBDatasetLoader()
        self.results = {}

    def run_fedot_baseline(self, X_train, y_train, X_test, y_test, problem_type):
        """–ó–∞–ø—É—Å–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ Fedot –±–µ–∑ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print("–ó–∞–ø—É—Å–∫ Fedot baseline...")

        start_time = time.time()
        baseline_params = AmlbExperimentDataset.FEDOT_BASELINE_PRESET.value
        baseline_params['problem'] = problem_type
        fedot_model = Fedot(**baseline_params)
        fedot_model.fit(X_train, y_train)
        predictions = fedot_model.predict(X_test)

        training_time = time.time() - start_time
        metrics = self._calculate_metrics(y_test, predictions, problem_type)
        metrics['training_time'] = training_time
        metrics['data_size'] = len(X_train)

        return metrics

    def run_fedot_sampling_ensemble(self, X_train, y_train, X_test, y_test, problem_type):
        """–ó–∞–ø—É—Å–∫ Fedot —Å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–º —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        print("–ó–∞–ø—É—Å–∫ Fedot + Sampling-Zoo ensemble...")

        start_time = time.time()

        # –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å —Å —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        ensemble = FedotSamplingEnsemble(problem=problem_type,
                                         partitioner_config=AmlbExperimentDataset.SAMPLING_PRESET.value,
                                         fedot_config=AmlbExperimentDataset.FEDOT_PRESET.value,
                                         ensemble_method='weighted'
                                         )

        # –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –ø–∞—Ä—Ç–∏—Ü–∏–∏
        partitions = ensemble.prepare_data_partitions(X_train, y_train)

        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–∞—Ä—Ç–∏—Ü–∏—è—Ö
        ensemble.train_partition_models(partitions)

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è
        predictions = ensemble.ensemble_predict(X_test)

        training_time = time.time() - start_time
        metrics = self._calculate_metrics(y_test, predictions, problem_type)
        metrics['training_time'] = training_time
        metrics['data_size'] = len(X_train)
        metrics['n_partitions'] = len(ensemble.models)
        metrics['partition_metrics'] = ensemble.partition_metrics

        return metrics, ensemble

    def _calculate_metrics(self, y_true, y_pred, problem_type):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"""
        if problem_type == 'classification':
            return {
                'accuracy': accuracy_score(y_true, y_pred),
                'f1_macro': f1_score(y_true, y_pred, average='macro'),
                'f1_weighted': f1_score(y_true, y_pred, average='weighted')
            }
        else:  # regression
            return {
                'mse': mean_squared_error(y_true, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
                'r2': r2_score(y_true, y_pred)
            }

    def run_experiment_on_dataset(self, dataset_info):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –Ω–∞ –æ–¥–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ"""
        print(f"\n{'=' * 50}")
        print(f"–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢: {dataset_info['name']}")
        print(f"{'=' * 50}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        X, y, dataset_info = self.loader.load_dataset(dataset_info)
        if X is None:
            return None

        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
        X_train, X_test, y_train, y_test = self.loader.prepare_train_test(X, y)

        results = {
            'dataset': dataset_info,
            'train_size': len(X_train),
            'test_size': len(X_test)
        }

        # 1. Fedot baseline
        print("\n1. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Fedot baseline...")
        try:
            baseline_metrics = self.run_fedot_baseline(
                X_train, y_train, X_test, y_test,
                dataset_info['type']
            )
            results['fedot_baseline'] = baseline_metrics
            print(f"   Baseline metrics: {baseline_metrics}")
        except Exception as e:
            print(f"   –û—à–∏–±–∫–∞ –≤ baseline: {str(e)}")
            results['fedot_baseline'] = {'error': str(e)}

        # 2. Fedot + Sampling-Zoo
        print("\n2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Fedot + Sampling-Zoo...")
        try:
            sampling_metrics, ensemble_model = self.run_fedot_sampling_ensemble(
                X_train, y_train, X_test, y_test,
                dataset_info['type']
            )
            results['fedot_sampling'] = sampling_metrics
            print(f"   Sampling ensemble metrics: {sampling_metrics}")
        except Exception as e:
            print(f"   –û—à–∏–±–∫–∞ –≤ sampling ensemble: {str(e)}")
            results['fedot_sampling'] = {'error': str(e)}

        # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å AMLB benchmark (–∑–∞–≥–ª—É—à–∫–∞ - –Ω—É–∂–Ω—ã —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–∞—Ç—å–∏)
        print("\n3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å AMLB benchmark...")
        amlb_comparison = self._compare_with_amlb_benchmark(dataset_info['name'], results)
        results['amlb_comparison'] = amlb_comparison

        return results

    def _compare_with_amlb_benchmark(self, dataset_name, results):
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å AMLB benchmark"""
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–∞—Ç—å–∏ AMLB
        # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ —É–ª—É—á—à–µ–Ω–∏—è–º–∏

        amlb_baselines = AmlbExperimentDataset.AMLB_EXPERIMENT_RESULTS.value

        comparison = {}
        if dataset_name in amlb_baselines:
            baseline = amlb_baselines[dataset_name]
            our_results = results.get('fedot_sampling', {})

            for metric, amlb_value in baseline.items():
                if metric in our_results:
                    improvement = our_results[metric] - amlb_value
                    comparison[metric] = {
                        'amlb': amlb_value,
                        'our_result': our_results[metric],
                        'improvement': improvement,
                        'improvement_pct': (improvement / amlb_value) * 100
                    }

        return comparison

    def run_full_benchmark(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –Ω–∞ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö"""
        all_datasets = (self.loader.get_classification_datasets() +
                        self.loader.get_regression_datasets())

        for dataset_info in all_datasets[:3]:  # –ù–∞—á–Ω–µ–º —Å 3 –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞
            result = self.run_experiment_on_dataset(dataset_info)
            if result:
                self.results[dataset_info['name']] = result

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                self.save_results()

    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
        import os
        os.makedirs(self.results_path, exist_ok=True)

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"{self.results_path}/experiment_results_{timestamp}.json"

        with open(filename, 'w') as f:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy types –≤ native Python types –¥–ª—è JSON
            def convert_types(obj):
                if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,
                                    np.int16, np.int32, np.int64, np.uint8,
                                    np.uint16, np.uint32, np.uint64)):
                    return int(obj)
                elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):
                    return float(obj)
                elif isinstance(obj, (np.ndarray,)):
                    return obj.tolist()
                return obj

            json.dump(self.results, f, indent=2, default=convert_types)

        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç"""
        print("\n" + "=" * 70)
        print("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê")
        print("=" * 70)

        for dataset_name, result in self.results.items():
            print(f"\nüìä –î–ê–¢–ê–°–ï–¢: {dataset_name}")
            print(f"   –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {result['train_size']} train, {result['test_size']} test")

            baseline = result.get('fedot_baseline', {})
            sampling = result.get('fedot_sampling', {})

            if 'error' not in baseline and 'error' not in sampling:
                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                if 'accuracy' in baseline:  # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                    print(f"   –¢–æ—á–Ω–æ—Å—Ç—å:")
                    print(f"     Baseline: {baseline['accuracy']:.4f}")
                    print(f"     Sampling: {sampling['accuracy']:.4f}")
                    improvement = sampling['accuracy'] - baseline['accuracy']
                    print(f"     –£–ª—É—á—à–µ–Ω–∏–µ: {improvement:+.4f}")

                elif 'rmse' in baseline:  # –†–µ–≥—Ä–µ—Å—Å–∏—è
                    print(f"   RMSE:")
                    print(f"     Baseline: {baseline['rmse']:.4f}")
                    print(f"     Sampling: {sampling['rmse']:.4f}")
                    improvement = baseline['rmse'] - sampling['rmse']  # –ú–µ–Ω—å—à–µ = –ª—É—á—à–µ
                    print(f"     –£–ª—É—á—à–µ–Ω–∏–µ: {improvement:+.4f}")

                # –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
                print(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:")
                print(f"     Baseline: {baseline['training_time']:.2f} —Å–µ–∫")
                print(f"     Sampling: {sampling['training_time']:.2f} —Å–µ–∫")
                time_diff = sampling['training_time'] - baseline['training_time']
                print(f"     –†–∞–∑–Ω–∏—Ü–∞: {time_diff:+.2f} —Å–µ–∫")
